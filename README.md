# 商品类目多级分类
参加大数据比赛时的题目，目的是为电商平台的商品进行多级分类  
数据清洗阶段，我们发现不加处理的输入数据，或者采用TDIDF方法提取关键词后输入，预测效果并不好，前者由于特征难提取，后者缺失了数据的特异性。所谓TFIDF方法的原理就是，一个词若在某个样本中出现的频率越高，而有该词的样本在全文档中越少，说明该词对这个样本有着越高的辨识度，越能成为关键词。在此基础上进行了改良，根据tfidf值为每个样本中的词进行排序，允许词汇重复。  
另外数据集中某些类目的数量差异过大，在梯度下降的时候会造成比较严重的数据倾斜问题，针对类目过少的样本进行了适量的重复，并打乱文本顺序，实现数据增强。  
模型方面采用了集成学习的思想。使用单一模型很可能造成过拟合的问题。采用了Stacking方法。设计了两层的结构，第一层模型有三个基本模型，为弱学习器；第二层有一个强学习器。将第一层三种不同的模型对数据集的概率输出整合，作为第二层的输入，最终得到标签预测。为了避免训练集训练出来的模型反过来预测训练集，这会造成过拟合，为此采用了K折交叉验证方法。  
在第一层中采用的模型有textcnn网络，基于Lstm的双向GRU网络，CNN与RNN串联网络，这些都是构造差异大但预测效果相近的模型。  
为了提高单个网络的性能，还采用了孪生网络和自编码器的相关技术。在数据集中不仅有word信息，还有character信息，将这两种截然不同的信息分别输入网络的两个输入端，这就构成了一个比较简单的伪孪生网络。  
在设计网络时，针对网络无法准确地进行数据特征的提取这一点，我们采用自编码器进行缓解。正向特征提取为编码过程，反过来为解码过程，构建原数据和反解码之间的重构误差，重构误差小说明特征提取到位。网络在训练的时候要尽力减小这个重构误差。  
参数不同，训练数据不同，训练方式不同，训练模型不同的架构，预测出来的ans是肯定存在差异的。对此设计了一种决策树，利用不同级之间的从属关系，引入多任务协作的相关思想，主要针对class3进行了结果上的投票仲裁，实现了准确率的提升。具体来说，比如有五个ans，先全员参与class1和class2的投票仲裁出民心所向的结果。针对class3，如果某一成员的class1与class3之间，class2和class3之间同时不满足从属关系，则作弃票处理。最终残余的成员参与class3的投票。若全员弃票，则视情况从上一级的附属级中随机选取：若class2-class3满足从属关系，则从class2的附属级中选取，若不满足则从class1的附属级中选取。

